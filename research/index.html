<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Towards Accessibility Assessment Tools for the Internet of Things"><title>Research | Accessible IoT</title><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap" rel=stylesheet><link rel=stylesheet href=/css/main.css></head><body><div class=site-wrapper><aside class=sidebar><div class=sidebar-header><a href=/ class=site-title>Accessible IoT</a></div><nav class=sidebar-nav><ul><li><a href=/>Home</a></li><li><a href=/research/ class=active>Research</a></li><li><a href=/timeline/>Timeline</a></li><li><a href=/news/>News</a></li><li><a href=/background/>Background</a></li><li><a href=/team/>Team</a></li></ul></nav></aside><header class=mobile-header><a href=/ class=mobile-title>Accessible IoT</a><nav class=mobile-nav><ul><li><a href=/>Home</a></li><li><a href=/research/ class=active>Research</a></li><li><a href=/timeline/>Timeline</a></li><li><a href=/news/>News</a></li><li><a href=/background/>Background</a></li><li><a href=/team/>Team</a></li></ul></nav></header><main class=main-content><div class=container><h1>Research</h1><p class=intro>Publications from the Accessible IoT project (2021-2025) under JST Presto Grant JPMJPR2132</p><div class=stats-grid><div class=stat-card><div class=stat-value>30</div><div class=stat-label>Publications</div></div><div class=stat-card><div class=stat-value>5</div><div class=stat-label>Years</div></div><div class=stat-card><div class=stat-value>29</div><div class=stat-label>Research Themes</div></div></div><section><h2>2025</h2><article class=publication-card><h3>Pro's Eyes: A Wearable System for Synchronous and Asynchronous Observational Pattern Learning</h3><p class=publication-venue>SIGGRAPH Asia 2025 Emerging Technologies</p><p class=publication-authors>Qing Zhang, Jing Huang, Yuta Itoh, Thad Starner, Kai Kunze, Jun Rekimoto</p><p><strong>Key Contribution:</strong> Wearable system enabling both synchronous and asynchronous observational pattern learning from experts</p><div class=publication-excerpt><p>Pro&rsquo;s Eyes is a wearable system that enables observational pattern learning from experts in both synchronous and asynchronous modes. The system captures and analyzes expert behavior patterns, facilitating skill transfer and learning through smart glasses technology.</p></div><div class=theme-badges><span class=theme-badge>smart-eyewear</span>
<span class=theme-badge>skill-learning</span>
<span class=theme-badge>educational-tools</span></div><div class=publication-links><a href=/papers/zhang2025pro.pdf target=_blank>PDF</a></div></article><article class=publication-card><h3>A Multimodal Wearable Sensing System for Vocal Muscle Biofeedback in Singing Pitch Training</h3><p class=publication-venue>UbiComp 2025</p><p class=publication-authors>Kanyu Chen, Akira Kato, Kai Kunze</p><p><strong>Key Contribution:</strong> Multimodal wearable system providing real-time biofeedback for vocal muscle control during singing pitch training</p><div class=publication-excerpt><p>This paper presents a multimodal wearable sensing system designed to provide vocal muscle biofeedback during singing pitch training. The system helps users develop better control over their vocal muscles through real-time physiological feedback.</p></div><div class=theme-badges><span class=theme-badge>wearable-iot</span>
<span class=theme-badge>physiological-sensing</span>
<span class=theme-badge>skill-learning</span></div><div class=publication-links><a href=/papers/chen2025multimodal.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3714394.3750550 target=_blank>DOI</a></div></article><article class=publication-card><h3>Biosensing, Enhanced Senses and Experience Design for Augmented Humans</h3><p class=publication-venue>UbiComp 2025</p><p class=publication-authors>Jonna Häkkilä, Jani Mäntyjärvi, Zhengya Gong, Heiko Müller, Kati Pettersson, Ashley Colley, Roope Raisamo, Kai Kunze, Albrecht Schmidt</p><p><strong>Key Contribution:</strong> Workshop exploring biosensing and enhanced senses for augmented human experiences</p><div class=publication-excerpt><p>This workshop paper explores the intersection of biosensing, enhanced senses, and experience design for augmented humans. It brings together researchers and practitioners to discuss how physiological sensing can create novel human augmentation experiences.</p></div><div class=theme-badges><span class=theme-badge>physiological-sensing</span>
<span class=theme-badge>human-augmentation</span>
<span class=theme-badge>experience-design</span></div><div class=publication-links><a href=/papers/hakkila2025biosensing.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3714394.3750568 target=_blank>DOI</a></div></article><article class=publication-card><h3>Conscious or Unconscious Meditation? Haptic Interaction Design in Meditation Augmentation Using Physiological Sensing</h3><p class=publication-venue>UbiComp 2025</p><p class=publication-authors>Danyang Peng, Kanyu Chen, Yun Suen Pai, Giulia Barbareschi, Kouta Minamizawa, Kai Kunze</p><p><strong>Key Contribution:</strong> Exploration of haptic interaction design for meditation augmentation using physiological sensing to support both conscious and unconscious practices</p><div class=publication-excerpt><p>This paper explores haptic interaction design for meditation augmentation, examining how physiological sensing can guide both conscious and unconscious meditation practices. The work investigates how different haptic feedback patterns can enhance meditative states.</p></div><div class=theme-badges><span class=theme-badge>haptic-feedback</span>
<span class=theme-badge>physiological-sensing</span>
<span class=theme-badge>wellbeing</span></div><div class=publication-links><a href=/papers/peng2025conscious.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3714394.3756165 target=_blank>DOI</a></div></article><article class="publication-card featured"><h3>EchoSense: Frontal Haptic Navigation in VR towards Biomimetic Empathy</h3><p class=publication-venue>UbiComp 2025</p><p class=publication-authors>Danyang Peng, Yihou Wang, Antony Tang, Ximing Shen, Yun Suen Pai, Giulia Barbareschi, Iain Anderson, Kouta Minamizawa, Kai Kunze</p><p><strong>Key Contribution:</strong> Novel frontal haptic navigation system for VR designed to foster biomimetic empathy and improve accessibility</p><div class=publication-excerpt><p>EchoSense presents a frontal haptic navigation system for VR environments that aims to foster biomimetic empathy. The system provides innovative haptic feedback for navigation, improving accessibility in virtual reality and enabling users to experience spatial awareness similar to biological echo-location.</p></div><div class=theme-badges><span class=theme-badge>haptic-feedback</span>
<span class=theme-badge>virtual-reality</span>
<span class=theme-badge>inclusive-design</span>
<span class=theme-badge>accessibility</span></div><div class=publication-links><a href=/papers/peng2025echosense.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3714394.3754428 target=_blank>DOI</a></div></article><article class=publication-card><h3>Exploring Singing Breath: Physiological Insights and Directions for Breath-Aware Augmentation in Mixed Reality Design</h3><p class=publication-venue>UbiComp 2025</p><p class=publication-authors>Kanyu Chen, Zhuang Chang, Qianyuan Zou, Kai Kunze</p><p><strong>Key Contribution:</strong> Physiological study of singing breath patterns with design directions for breath-aware mixed reality augmentation</p><div class=publication-excerpt><p>This paper explores the physiological aspects of singing breath control and proposes design directions for breath-aware augmentation in mixed reality. The work provides insights into respiratory patterns during singing and how they can be leveraged for immersive training experiences.</p></div><div class=theme-badges><span class=theme-badge>physiological-sensing</span>
<span class=theme-badge>mixed-reality</span>
<span class=theme-badge>skill-learning</span></div><div class=publication-links><a href=/papers/chen2025exploring.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3714394.3756159 target=_blank>DOI</a></div></article><article class=publication-card><h3>Introduction of the VCSD Dataset: A Vocal Cords Dataset Using EMG and Ultrasonography for Singing Pitch Skill Recognition</h3><p class=publication-venue>UbiComp 2025</p><p class=publication-authors>Kanyu Chen, Erwin Wu, Chen-Chieh Liao, Daichi Saito, Yichen Peng, Kato Akira, Hideki Koike, Kai Kunze</p><p><strong>Key Contribution:</strong> First public dataset of vocal cord activity combining EMG and ultrasonography for singing pitch skill recognition</p><div class=publication-excerpt><p>This paper introduces VCSD (Vocal Cords for Singing Dataset), a novel dataset combining EMG and ultrasonography data for singing pitch skill recognition. The dataset provides a valuable resource for researchers working on vocal training systems and physiological sensing.</p></div><div class=theme-badges><span class=theme-badge>physiological-sensing</span>
<span class=theme-badge>datasets</span>
<span class=theme-badge>skill-learning</span></div><div class=publication-links><a href=/papers/chen2025introduction.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3714394.3754407 target=_blank>DOI</a></div></article><article class=publication-card><h3>2nd International Workshop on Mobile Cognitive-Augmenting and Cognition-Altering Technologies (CAT) in Human-Centered AI</h3><p class=publication-venue>MobileHCI 2025</p><p class=publication-authors>Agnes Gruenerbl, Jan Spilski, Giulia Barbareschi, Kai Kunze, Passant ElAgroudy, Thomas Lachmann, Paul Lukowicz</p><p><strong>Key Contribution:</strong> Second edition of workshop advancing research in mobile cognitive augmentation and human-centered AI</p><div class=publication-excerpt><p>This workshop paper presents the second International Workshop on Mobile Cognitive-Augmenting and Cognition-Altering Technologies (mobiCHAI). Building on the first workshop, it continues to explore mobile technologies for cognitive augmentation within human-centered AI frameworks.</p></div><div class=theme-badges><span class=theme-badge>cognitive-augmentation</span>
<span class=theme-badge>mobile-computing</span>
<span class=theme-badge>human-centered-ai</span></div><div class=publication-links><a href=/papers/gruenerbl20252nd.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3737821.3743747 target=_blank>DOI</a></div></article><article class=publication-card><h3>Spread Your Wings: Demonstrating a Soft Floating Robotic Avatar with Flapping Wings for Novel Physical Interactions</h3><p class=publication-venue>SIGGRAPH 2025 Emerging Technologies</p><p class=publication-authors>Mingyang Xu, Yulan Ju, Qing Zhang, Christopher Changmok Kim, Qingyuan Gao, Yun Suen Pai, Giulia Barbareschi, Matthias Hoppe, Kai Kunze, Kouta Minamizawa</p><p><strong>Key Contribution:</strong> Soft floating robotic avatar with flapping wings enabling novel affective physical interactions</p><div class=publication-excerpt><p>This demonstration presents a soft floating robotic avatar with flapping wings that enables novel forms of physical interaction. The robot builds on previous work (Cuddle robot) to explore how wing-based movements can create engaging and affective human-robot interactions.</p></div><div class=theme-badges><span class=theme-badge>assistive-robotics</span>
<span class=theme-badge>haptic-feedback</span>
<span class=theme-badge>human-robot-interaction</span></div><div class=publication-links><a href=/papers/xu2025spread.pdf target=_blank>PDF</a></div></article><article class=publication-card><h3>BodyPursuits</h3><p class=publication-subtitle>Exploring Smooth Pursuit Gaze Interaction Based on Body Motion Targets</p><p class=publication-venue>ETRA 2025</p><p class=publication-authors>Anja Hansen, Sarah Makarem, Kai Kunze, Yexu Zhou, Michael Thomas Knierim, Christopher Clarke, Hans Gellersen, Michael Beigl, Tobias Röddiger</p><p><strong>Key Contribution:</strong> Novel gaze interaction technique based on smooth pursuit eye movements tracking body motion, enabling hands-free interaction</p><div class=publication-excerpt><p>This research explores how the natural eye movement pattern of smooth pursuit can be used for interaction with IoT systems and wearable devices. By tracking how users&rsquo; eyes follow their own body motions, the system creates new opportunities for hands-free control.</p><p>The technique has particular relevance for accessibility, enabling people with limited hand mobility to interact with technology using natural body movements and gaze. It represents an innovative approach to inclusive interface design in the context of ubiquitous computing.</p></div><div class=theme-badges><span class=theme-badge>cognitive-augmentation</span></div><div class=publication-links><a href=/papers/hansen2025bodypursuits.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3715669.3723110 target=_blank>DOI</a></div></article><article class=publication-card><h3>Eye-Tracking for Cognitive Well-Being</h3><p class=publication-subtitle>Balancing Detection and Ethical Feedback</p><p class=publication-venue>ETRA 2025</p><p class=publication-authors>Christopher Changmok Kim, Matthias Hoppe, Kai Kunze</p><p><strong>Key Contribution:</strong> Framework for ethical eye-tracking-based cognitive well-being monitoring that balances detection accuracy with user privacy and autonomy</p><div class=publication-excerpt><p>As eye-tracking becomes increasingly integrated into wearable devices and IoT systems, questions arise about how to ethically monitor and provide feedback about users&rsquo; cognitive states. This research addresses these concerns head-on, proposing design principles that prioritize user autonomy and well-being.</p><p>The work is particularly relevant for accessibility applications where cognitive monitoring could support people with attention difficulties, mental health challenges, or neurodivergent individuals, while respecting their privacy and agency.</p></div><div class=theme-badges><span class=theme-badge>cognitive-augmentation</span>
<span class=theme-badge>smart-eyewear</span></div><div class=publication-links><a href=/papers/kim2025eye.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3715669.3726817 target=_blank>DOI</a></div></article><article class=publication-card><h3>TIEboard: A Digital Educational Tool for Kids Geometric Learning</h3><p class=publication-venue>Proc. ACM IMWUT</p><p class=publication-authors>Arooj Zaidi, Giulia Barbareschi, Kai Kunze, Yun Suen Pai, Junichi Yamaoka</p><p><strong>Key Contribution:</strong> Interactive digital tool that makes geometric learning accessible and engaging for children</p><div class=publication-excerpt><p>TIEboard represents an innovative approach to making mathematics education more accessible and inclusive for children. By combining tangible interaction with digital feedback, the tool creates an engaging learning environment that supports diverse learning styles.</p><p>The research demonstrates how IoT-enabled educational tools can bridge the gap between abstract mathematical concepts and concrete, hands-on learning experiences.</p></div><div class=theme-badges><span class=theme-badge>educational-tools</span>
<span class=theme-badge>inclusive-design</span></div><div class=publication-links><a href=/papers/zaidi2025tieboard.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3729478 target=_blank>DOI</a></div></article><article class="publication-card featured"><h3>Sticking With Electronics for Crafting Practices</h3><p class=publication-subtitle>An Inclusive Approach to Promote Making Literacy Among Older Adults</p><p class=publication-venue>CHI 2025</p><p class=publication-authors>Giulia Barbareschi, Chihiro Sato, Seray Senyer, Michael Pan Junpeng, Jianrui Zhao, Dunya Chen, Kirsten Ellis, Kai Kunze</p><p><strong>Key Contribution:</strong> Inclusive approach to teaching electronics and making skills to older adults through crafting practices</p><div class=publication-excerpt><p>This work addresses the digital divide by making electronics and IoT creation accessible to older adults. Through carefully designed crafting activities that incorporate electronics, the research shows how older adults can develop technical literacy while engaging in creative, meaningful activities.</p><p>The findings have important implications for inclusive design in IoT, showing that with appropriate support and methods, technology creation can be made accessible across age groups and technical backgrounds.</p></div><div class=theme-badges><span class=theme-badge>inclusive-design</span></div><div class=publication-links><a href=/papers/barbareschi2025sticking.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3706598.3714234 target=_blank>DOI</a></div></article><article class=publication-card><h3>Cuddle-Fish: Exploring a Soft Floating Robot with Flapping Wings for Physical Interactions</h3><p class=publication-venue>AHs 2025</p><p class=publication-authors>Mingyang Xu, Jiayi Shao, Yulan Ju, Ximing Shen, Qingyuan Gao, Weijen Chen, Qing Zhang, Yun Suen Pai, Giulia Barbareschi, Matthias Hoppe, Kouta Minamizawa, Kai Kunze</p><p><strong>Key Contribution:</strong> Novel soft floating robot design for safe and engaging physical interaction</p><div class=publication-excerpt><p>Cuddle-Fish presents an innovative soft floating robot with flapping wings designed for safe physical interactions. The soft materials and gentle motion make it suitable for therapeutic and assistive applications, particularly in contexts requiring calming, non-threatening robotic presence.</p></div><div class=theme-badges><span class=theme-badge>assistive-robotics</span></div><div class=publication-links><a href=/papers/xu2025cuddle.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3745900.3746080 target=_blank>DOI</a></div></article><article class="publication-card featured"><h3>MindSpace: Improving Relaxation Break and Performance Using a Device Exterting Tactile Sensation of Life-like Breathing Movement with Squeeze-like Deep Touch Pressure on Users' Upper Chest Area</h3><p class=publication-venue>Mensch und Computer 2025</p><p class=publication-authors>Misaki Kikuchi, Kanyu Chen, Rebecca Panskus, Dunya Chen, Keiko Okawa, Kai Kunze</p><p><strong>Key Contribution:</strong> Novel haptic device using life-like breathing movements and deep touch pressure to improve relaxation and performance</p><div class=publication-excerpt><p>MindSpace is a novel device that provides tactile sensations mimicking life-like breathing movements with squeeze-like deep touch pressure on the upper chest area. The system is designed to improve relaxation breaks and enhance performance through calming haptic feedback.</p></div><div class=theme-badges><span class=theme-badge>haptic-feedback</span>
<span class=theme-badge>cognitive-augmentation</span>
<span class=theme-badge>wellbeing</span></div><div class=publication-links><a href=/papers/kikuchi2025mindspace.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3743049.3743054 target=_blank>DOI</a></div></article></section><section><h2>2024</h2><article class="publication-card featured"><h3>OpenEarable ExG: Open-Source Hardware for Ear-Based Biopotential Sensing Applications</h3><p class=publication-venue>UbiComp 2024</p><p class=publication-authors>Philipp Lepold, Tobias Röddiger, Tobias King, Kai Kunze, Christoph Maurer, Michael Beigl</p><p><strong>Key Contribution:</strong> Open-source hardware platform for ear-based biopotential sensing, enabling accessible IoT health monitoring</p><div class=publication-excerpt><p>This paper introduces OpenEarable ExG, an innovative open-source hardware platform that democratizes ear-based biopotential sensing. By making the designs and schematics freely available, the research enables a wide range of applications in health monitoring, cognitive state detection, and accessibility tools.</p><p>The platform supports various biopotential signals including EOG (electrooculography), EMG (electromyography), and ECG (electrocardiography), all captured from the ear region. This positions OpenEarable as a key enabling technology for the Internet of Things in healthcare and accessibility contexts.</p></div><div class=theme-badges><span class=theme-badge>wearable-iot</span></div><div class=publication-links><a href=/papers/lepold2024open.pdf target=_blank>PDF</a></div></article><article class=publication-card><h3>mobiCHAI 2024: 1st International Workshop on Mobile Cognitive-Augmenting and Cognition-Altering Technologies (CAT) in Human-Centered AI</h3><p class=publication-venue>MobileHCI 2024</p><p class=publication-authors>Passant ElAgroudy, Jan Spilski, Giulia Barbareschi, Kai Kunze, Thomas Lachmann, Paul Lukowicz</p><p><strong>Key Contribution:</strong> First workshop establishing the research agenda for mobile cognitive augmentation technologies</p><div class=publication-excerpt><p>This workshop paper introduces the first International Workshop on Mobile Cognitive-Augmenting and Cognition-Altering Technologies (mobiCHAI). The workshop explores how mobile technologies can augment human cognitive capabilities within human-centered AI frameworks.</p></div><div class=theme-badges><span class=theme-badge>cognitive-augmentation</span>
<span class=theme-badge>mobile-computing</span>
<span class=theme-badge>human-centered-ai</span></div><div class=publication-links><a href=/papers/elagroudy2024mobichai.pdf target=_blank>PDF</a></div></article><article class="publication-card featured"><h3>Speech is Silver, Silence is Golden</h3><p class=publication-subtitle>Analyzing Micro-communication Strategies between Visually Impaired Runners and their Guides</p><p class=publication-venue>CHI 2024</p><p class=publication-authors>Giulia Barbareschi, Tarika Kumar, Christopher Changmok Kim, George Chernyshov, Kai Kunze</p><p><strong>Key Contribution:</strong> First study on non-verbal communication strategies between visually impaired runners and sighted guides</p><div class=publication-excerpt><p>This groundbreaking research explores the subtle communication patterns that enable visually impaired runners and their guides to move together effectively. The study reveals intricate verbal and non-verbal signaling strategies that have developed organically in the running community, providing insights for designing better assistive technologies for sports and physical activities.</p><p>Key findings include the importance of silence as a form of communication, indicating smooth coordination, and the role of micro-adjustments in maintaining synchronization between runner and guide.</p></div><div class=theme-badges><span class=theme-badge>visual-accessibility</span>
<span class=theme-badge>inclusive-design</span></div><div class=publication-links><a href=/papers/barbareschi2024speech.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3613904.3642000 target=_blank>DOI</a></div></article><article class="publication-card featured"><h3>A Novel Sensing Method and Its Empirical Study for Vocal Technique Analysis of Singing Pitch Control: Combining Surface EMG with Ultrasonography</h3><p class=publication-venue>Augmented Humans 2024</p><p class=publication-authors>Kanyu Chen, Kato Akira, Chen-Chieh Liao, Erwin Wu, Kai Kunze</p><p><strong>Key Contribution:</strong> Novel multimodal sensing approach combining EMG and ultrasonography for analyzing vocal techniques in singing</p><div class=publication-excerpt><p>This paper introduces a novel sensing method that combines surface EMG with ultrasonography to analyze vocal techniques during singing pitch control. The multimodal approach provides deeper insights into the physiological mechanisms of singing and opens new possibilities for vocal training systems.</p></div><div class=theme-badges><span class=theme-badge>wearable-iot</span>
<span class=theme-badge>physiological-sensing</span>
<span class=theme-badge>skill-learning</span></div><div class=publication-links><a href=/papers/chen2024novel.pdf target=_blank>PDF</a></div></article></section><section><h2>2023</h2><article class=publication-card><h3>Soma Express Kit</h3><p class=publication-subtitle>Understanding the Somaesthetic Experience of People with Visual Impairment</p><p class=publication-venue>IoT 2023</p><p class=publication-authors>Michi Kanda, Kai Kunze</p><p><strong>Key Contribution:</strong> Novel IoT toolkit that leverages heightened somatosensory capacities of people with visual impairments for cross-ability interaction</p><div class=publication-excerpt><p>This research introduces an innovative approach to understanding and sharing the embodied experiences of people with visual impairments. The Soma Express Kit uses IoT sensors and multi-sensory feedback to create new channels of communication between people with and without visual impairments.</p><p>By embracing the somaesthetic potential of people with visual impairments, this work fosters empathy and enables richer collaborative cross-ability interactions. The toolkit represents a significant contribution to inclusive IoT design, moving beyond traditional assistive technology paradigms.</p></div><div class=theme-badges><span class=theme-badge>visual-accessibility</span>
<span class=theme-badge>wearable-iot</span></div><div class=publication-links><a href=/papers/kanda2023soma.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3627050.3631571 target=_blank>DOI</a></div></article><article class="publication-card featured"><h3>I am both here and there</h3><p class=publication-subtitle>Parallel Control of Multiple Robotic Avatars by Disabled Workers in a Café</p><p class=publication-venue>CHI 2023</p><p class=publication-authors>Giulia Barbareschi, Midori Kawaguchi, Hiroaki Kato, Masato Nagahiro, Kazuaki Takeuchi, Yoshifumi Shiiba, Shunichi Kasahara, Kai Kunze, Kouta Minamizawa</p><p><strong>Key Contribution:</strong> Demonstrated that disabled workers can effectively control multiple robotic avatars simultaneously in a real café environment</p><div class=publication-excerpt><p>A groundbreaking study conducted in a real café environment where disabled workers operated multiple robotic avatars in parallel. The research demonstrates that people with disabilities possess specific competencies that enhance their ability to manage multiple embodied presences simultaneously.</p><p>The findings have significant implications for employment opportunities and workplace accessibility, showing how assistive robotics can create new forms of meaningful work for people with mobility impairments.</p><p>This work was featured in multiple accessibility newsletters and demonstrates the practical application of IoT and robotics in creating inclusive workspaces.</p></div><div class=theme-badges><span class=theme-badge>assistive-robotics</span>
<span class=theme-badge>inclusive-design</span></div><div class=publication-links><a href=/papers/barbareschi2023both.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3544548.3581124 target=_blank>DOI</a></div></article><article class=publication-card><h3>Affective Umbrella--A Wearable System to Visualize Heart and Electrodermal Activity, towards Emotion Regulation through Somaesthetic Appreciation</h3><p class=publication-venue>Augmented Humans 2023</p><p class=publication-authors>Kanyu Chen, Jiawen Han, Holger Baldauf, Ziyue Wang, Dunya Chen, Akira Kato, Jamie A Ward, Kai Kunze</p><p><strong>Key Contribution:</strong> Wearable system that visualizes physiological signals to support emotion regulation through somaesthetic appreciation</p><div class=publication-excerpt><p>The Affective Umbrella is a wearable system that visualizes heart and electrodermal activity in real-time. The work explores how somaesthetic appreciation of one&rsquo;s own physiological signals can support emotion regulation and self-awareness.</p></div><div class=theme-badges><span class=theme-badge>wearable-iot</span>
<span class=theme-badge>physiological-sensing</span>
<span class=theme-badge>affective-computing</span></div><div class=publication-links><a href=/papers/chen2023affective.pdf target=_blank>PDF</a></div></article><article class=publication-card><h3>First Bite/Chew: distinguish typical allergic food by two IMUs</h3><p class=publication-venue>Augmented Humans 2023</p><p class=publication-authors>Juling Li, Xiongqi Wang, Junyu Chen, Thad Starner, George Chernyshov, Jing Huang, Yifei Huang, Kai Kunze, Qing Zhang</p><p><strong>Key Contribution:</strong> Novel IMU-based system for detecting allergic foods through bite and chew pattern recognition</p><div class=publication-excerpt><p>This paper presents a wearable system using two IMU sensors to detect typical allergic foods by analyzing bite and chew patterns. The work offers a novel approach to food allergy detection that could help users avoid allergen exposure.</p></div><div class=theme-badges><span class=theme-badge>wearable-iot</span>
<span class=theme-badge>health-monitoring</span>
<span class=theme-badge>food-detection</span></div><div class=publication-links><a href=/papers/li2023first.pdf target=_blank>PDF</a></div></article></section><section><h2>2022</h2><article class="publication-card featured"><h3>Seeing our Blind Spots</h3><p class=publication-subtitle>Smart Glasses-based Simulation to Increase Design Students' Awareness of Visual Impairment</p><p class=publication-venue>UIST 2022</p><p class=publication-authors>Qing Zhang, Giulia Barbareschi, Yifei Huang, Juling Li, Yun Suen Pai, Jamie Ward, Kai Kunze</p><p><strong>Key Contribution:</strong> Dynamic smart glasses-based simulation system that considers eye movements, improving accessibility awareness training</p><div class=publication-excerpt><p>Traditional visual impairment simulation tools are static and fail to account for dynamic eye movements. This research introduces a smart glasses-based system that provides realistic, dynamic simulations of various visual impairments.</p><p>The system was evaluated with design students, demonstrating significant improvements in their awareness and understanding of visual accessibility challenges. Questionnaires and qualitative feedback confirmed that the dynamic, eye-movement-aware simulation helped participants develop more empathetic and informed approaches to inclusive design.</p><p>This work bridges the gap between accessibility theory and practice, providing tangible tools for educating the next generation of designers about inclusive IoT systems.</p></div><div class=theme-badges><span class=theme-badge>smart-eyewear</span>
<span class=theme-badge>visual-accessibility</span></div><div class=publication-links><a href=/papers/zhang2022seeing.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3526113.3545687 target=_blank>DOI</a></div></article><article class=publication-card><h3>EyeMove-Towards Mobile Authentication using EOG Glasses</h3><p class=publication-venue>Augmented Humans 2022</p><p class=publication-authors>Kirill Ragozin, Karola Marky, Jie Lu, Kai Kunze</p><p><strong>Key Contribution:</strong> Novel mobile authentication approach using electrooculography captured by smart glasses</p><div class=publication-excerpt><p>EyeMove explores using EOG (electrooculography) glasses for mobile authentication. The system leverages eye movement patterns captured through wearable glasses as a biometric authentication method, offering a novel approach to secure access control.</p></div><div class=theme-badges><span class=theme-badge>smart-eyewear</span>
<span class=theme-badge>authentication</span>
<span class=theme-badge>security</span></div><div class=publication-links><a href=/papers/ragozin2022eyemove.pdf target=_blank>PDF</a></div></article><article class="publication-card featured"><h3>Towards Applying Pneumatic Gel Muscles to Augment Plantar Flexor Muscle Stretching for Children with Cerebral Palsy</h3><p class=publication-venue>Augmented Humans 2022</p><p class=publication-authors>Zilan Chen, Sujuan Wang, Swagata Das, Yuichi Kurita, Takashi Goto, Chun Zhai, Lei Xu, Kai Kunze</p><p><strong>Key Contribution:</strong> Novel application of pneumatic gel muscles for augmenting plantar flexor muscle stretching in children with cerebral palsy</p><div class=publication-excerpt><p>This paper explores the potential of Pneumatic Gel Muscles (PGM) technology for assisting children with cerebral palsy. The work investigates how soft actuators can be used to augment plantar flexor muscle stretching, offering a novel approach to rehabilitation therapy.</p></div><div class=theme-badges><span class=theme-badge>assistive-technology</span>
<span class=theme-badge>haptic-feedback</span>
<span class=theme-badge>inclusive-design</span></div><div class=publication-links><a href=/papers/chen2022towards.pdf target=_blank>PDF</a></div></article><article class=publication-card><h3>Ethereal Phenomena-Interactive Art, Meditation, and Breathing Biofeedback: From Mind and Body Wellness Towards Self-Transcendence</h3><p class=publication-venue>TEI 2022</p><p class=publication-authors>Silvana Malaver Turbay, Igor Igorevich Segrovets, George Chernyshov, Jiawen Han, Christopher Changmok Kim, Kai Kunze</p><p><strong>Key Contribution:</strong> Extended exploration of breathing biofeedback in interactive art, connecting mind-body wellness to self-transcendence</p><div class=publication-excerpt><p>This extended work on Ethereal Phenomena presents an interactive art installation that uses breathing biofeedback to facilitate meditation and self-transcendence. The system bridges mind-body wellness practices with technological augmentation through real-time physiological sensing and visualization.</p></div><div class=theme-badges><span class=theme-badge>artistic-expression</span>
<span class=theme-badge>physiological-sensing</span>
<span class=theme-badge>cognitive-augmentation</span></div><div class=publication-links><a href=/papers/malaver2022ethereal.pdf target=_blank>PDF</a></div></article><article class="publication-card featured"><h3>Human--Computer Integration: Towards Integrating the Human Body with the Computational Machine</h3><p class=publication-venue>Foundations and Trends in Human-Computer Interaction</p><p class=publication-authors>Nathan Semertzidis, Josh Andres, Martin Weigel, Suranga Nanayakkara, Rakesh Patibanda, Zhuying Li, Paul Strohmeier, Jarrod Knibbe, Stefan Greuter, Marianna Obrist, Kai Kunze</p><p><strong>Key Contribution:</strong> Comprehensive survey establishing theoretical foundations for human-computer integration research</p><div class=publication-excerpt><p>This comprehensive survey paper establishes the theoretical foundations for human-computer integration (HCI), exploring how the human body can be integrated with computational machines. The work provides a framework for understanding and advancing research in human augmentation and embodied interaction.</p></div><div class=theme-badges><span class=theme-badge>cognitive-augmentation</span>
<span class=theme-badge>human-augmentation</span>
<span class=theme-badge>theoretical-foundations</span></div><div class=publication-links><a href=/papers/semertzidis2022human.pdf target=_blank>PDF</a></div></article></section><section><h2>2021</h2><article class=publication-card><h3>Ethereal Phenomena</h3><p class=publication-venue>SIGGRAPH Asia 2021 Art Gallery</p><p class=publication-authors>S Malaver, N Nieto, I Segrovets, C Rizzi, G Chernyshov, C Kim, Kai Kunze</p><p><strong>Key Contribution:</strong> Interactive art installation exploring meditation and breathing through physiological sensing and visualization</p><div class=publication-excerpt><p>Ethereal Phenomena is an interactive art installation that explores the connection between meditation, breathing patterns, and visual representation. The work uses biofeedback to create immersive experiences that visualize physiological states.</p></div><div class=theme-badges><span class=theme-badge>artistic-expression</span>
<span class=theme-badge>physiological-sensing</span>
<span class=theme-badge>interactive-media</span></div><div class=publication-links><a href=/papers/malaver2021ethereal.pdf target=_blank>PDF</a>
<a href=https://doi.org/10.1145/3476123.3487870 target=_blank>DOI</a></div></article><article class=publication-card><h3>Affective Umbrella--Towards a Novel Sensor Integrated Multimedia Platform Using Electrodermal and Heart Activity in an Umbrella Handle</h3><p class=publication-venue>MUM 2021</p><p class=publication-authors>Kanyu Chen, Jiawen Han, George Chernyshov, Christopher Kim, Ismael Rasa, Kai Kunze</p><p><strong>Key Contribution:</strong> Novel sensor-integrated platform embedded in an umbrella handle for capturing physiological signals in everyday contexts</p><div class=publication-excerpt><p>This paper introduces the Affective Umbrella, a novel platform that integrates electrodermal and heart activity sensors into an umbrella handle. The system explores unobtrusive physiological monitoring in everyday situations, turning a common object into a wearable sensing device.</p></div><div class=theme-badges><span class=theme-badge>wearable-iot</span>
<span class=theme-badge>physiological-sensing</span>
<span class=theme-badge>affective-computing</span></div><div class=publication-links><a href=/papers/chen2021affective.pdf target=_blank>PDF</a></div></article></section></div></main></div></body></html>