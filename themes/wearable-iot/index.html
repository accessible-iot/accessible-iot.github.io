<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Towards Accessibility Assessment Tools for the Internet of Things"><title>Wearable-Iot | Accessible IoT</title><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap" rel=stylesheet><link rel=stylesheet href=/css/main.css></head><body><div class=site-wrapper><aside class=sidebar><div class=sidebar-header><a href=/ class=site-title>Accessible IoT</a></div><nav class=sidebar-nav><ul><li><a href=/>Home</a></li><li><a href=/research/>Research</a></li><li><a href=/timeline/>Timeline</a></li><li><a href=/news/>News</a></li><li><a href=/background/>Background</a></li><li><a href=/team/>Team</a></li></ul></nav></aside><header class=mobile-header><a href=/ class=mobile-title>Accessible IoT</a><nav class=mobile-nav><ul><li><a href=/>Home</a></li><li><a href=/research/>Research</a></li><li><a href=/timeline/>Timeline</a></li><li><a href=/news/>News</a></li><li><a href=/background/>Background</a></li><li><a href=/team/>Team</a></li></ul></nav></header><main class=main-content><div class=container><h1>Wearable-Iot</h1><article class=card><h3><a href=https://accessible-iot.org/publications/chen2025multimodal/>A Multimodal Wearable Sensing System for Vocal Muscle Biofeedback in Singing Pitch Training</a></h3><p>This paper presents a multimodal wearable sensing system designed to provide vocal muscle biofeedback during singing pitch training. The system helps users develop better control over their vocal muscles through real-time physiological feedback.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/lepold2024openarable/>OpenEarable ExG: Open-Source Hardware for Ear-Based Biopotential Sensing Applications</a></h3><p>This paper introduces OpenEarable ExG, an innovative open-source hardware platform that democratizes ear-based biopotential sensing. By making the designs and schematics freely available, the research enables a wide range of applications in health monitoring, cognitive state detection, and accessibility tools.</p><p>The platform supports various biopotential signals including EOG (electrooculography), EMG (electromyography), and ECG (electrocardiography), all captured from the ear region. This positions OpenEarable as a key enabling technology for the Internet of Things in healthcare and accessibility contexts.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/chen2024novel/>A Novel Sensing Method and Its Empirical Study for Vocal Technique Analysis of Singing Pitch Control: Combining Surface EMG with Ultrasonography</a></h3><p>This paper introduces a novel sensing method that combines surface EMG with ultrasonography to analyze vocal techniques during singing pitch control. The multimodal approach provides deeper insights into the physiological mechanisms of singing and opens new possibilities for vocal training systems.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/kanda2023soma/>Soma Express Kit</a></h3><p>This research introduces an innovative approach to understanding and sharing the embodied experiences of people with visual impairments. The Soma Express Kit uses IoT sensors and multi-sensory feedback to create new channels of communication between people with and without visual impairments.</p><p>By embracing the somaesthetic potential of people with visual impairments, this work fosters empathy and enables richer collaborative cross-ability interactions. The toolkit represents a significant contribution to inclusive IoT design, moving beyond traditional assistive technology paradigms.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/chen2023affective/>Affective Umbrella--A Wearable System to Visualize Heart and Electrodermal Activity, towards Emotion Regulation through Somaesthetic Appreciation</a></h3><p>The Affective Umbrella is a wearable system that visualizes heart and electrodermal activity in real-time. The work explores how somaesthetic appreciation of one&rsquo;s own physiological signals can support emotion regulation and self-awareness.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/li2023first/>First Bite/Chew: distinguish typical allergic food by two IMUs</a></h3><p>This paper presents a wearable system using two IMU sensors to detect typical allergic foods by analyzing bite and chew patterns. The work offers a novel approach to food allergy detection that could help users avoid allergen exposure.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/chen2021affective/>Affective Umbrella--Towards a Novel Sensor Integrated Multimedia Platform Using Electrodermal and Heart Activity in an Umbrella Handle</a></h3><p>This paper introduces the Affective Umbrella, a novel platform that integrates electrodermal and heart activity sensors into an umbrella handle. The system explores unobtrusive physiological monitoring in everyday situations, turning a common object into a wearable sensing device.</p></article></div></main></div></body></html>