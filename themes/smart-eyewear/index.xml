<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Smart-Eyewear on Accessible IoT</title><link>https://accessible-iot.org/themes/smart-eyewear/</link><description>Recent content in Smart-Eyewear on Accessible IoT</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 10 Dec 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://accessible-iot.org/themes/smart-eyewear/index.xml" rel="self" type="application/rss+xml"/><item><title>Pro's Eyes: A Wearable System for Synchronous and Asynchronous Observational Pattern Learning</title><link>https://accessible-iot.org/publications/zhang2025pro/</link><pubDate>Wed, 10 Dec 2025 00:00:00 +0000</pubDate><guid>https://accessible-iot.org/publications/zhang2025pro/</guid><description>&lt;p&gt;Pro&amp;rsquo;s Eyes is a wearable system that enables observational pattern learning from experts in both synchronous and asynchronous modes. The system captures and analyzes expert behavior patterns, facilitating skill transfer and learning through smart glasses technology.&lt;/p&gt;</description></item><item><title>Eye-Tracking for Cognitive Well-Being</title><link>https://accessible-iot.org/publications/kim2025eye/</link><pubDate>Mon, 02 Jun 2025 00:00:00 +0000</pubDate><guid>https://accessible-iot.org/publications/kim2025eye/</guid><description>&lt;p&gt;As eye-tracking becomes increasingly integrated into wearable devices and IoT systems, questions arise about how to ethically monitor and provide feedback about users&amp;rsquo; cognitive states. This research addresses these concerns head-on, proposing design principles that prioritize user autonomy and well-being.&lt;/p&gt;
&lt;p&gt;The work is particularly relevant for accessibility applications where cognitive monitoring could support people with attention difficulties, mental health challenges, or neurodivergent individuals, while respecting their privacy and agency.&lt;/p&gt;</description></item><item><title>Seeing our Blind Spots</title><link>https://accessible-iot.org/publications/zhang2022seeing/</link><pubDate>Sat, 29 Oct 2022 00:00:00 +0000</pubDate><guid>https://accessible-iot.org/publications/zhang2022seeing/</guid><description>&lt;p&gt;Traditional visual impairment simulation tools are static and fail to account for dynamic eye movements. This research introduces a smart glasses-based system that provides realistic, dynamic simulations of various visual impairments.&lt;/p&gt;
&lt;p&gt;The system was evaluated with design students, demonstrating significant improvements in their awareness and understanding of visual accessibility challenges. Questionnaires and qualitative feedback confirmed that the dynamic, eye-movement-aware simulation helped participants develop more empathetic and informed approaches to inclusive design.&lt;/p&gt;</description></item><item><title>EyeMove-Towards Mobile Authentication using EOG Glasses</title><link>https://accessible-iot.org/publications/ragozin2022eyemove/</link><pubDate>Sun, 27 Feb 2022 00:00:00 +0000</pubDate><guid>https://accessible-iot.org/publications/ragozin2022eyemove/</guid><description>&lt;p&gt;EyeMove explores using EOG (electrooculography) glasses for mobile authentication. The system leverages eye movement patterns captured through wearable glasses as a biometric authentication method, offering a novel approach to secure access control.&lt;/p&gt;</description></item></channel></rss>