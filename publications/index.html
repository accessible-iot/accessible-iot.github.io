<!doctype html><html lang=en-us><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Towards Accessibility Assessment Tools for the Internet of Things"><title>Publications | Accessible IoT</title><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap" rel=stylesheet><link rel=stylesheet href=/css/main.css></head><body><div class=site-wrapper><aside class=sidebar><div class=sidebar-header><a href=/ class=site-title>Accessible IoT</a></div><nav class=sidebar-nav><ul><li><a href=/>Home</a></li><li><a href=/research/>Research</a></li><li><a href=/timeline/>Timeline</a></li><li><a href=/news/>News</a></li><li><a href=/background/>Background</a></li><li><a href=/team/>Team</a></li></ul></nav></aside><header class=mobile-header><a href=/ class=mobile-title>Accessible IoT</a><nav class=mobile-nav><ul><li><a href=/>Home</a></li><li><a href=/research/>Research</a></li><li><a href=/timeline/>Timeline</a></li><li><a href=/news/>News</a></li><li><a href=/background/>Background</a></li><li><a href=/team/>Team</a></li></ul></nav></header><main class=main-content><div class=container><h1>Publications</h1><article class=card><h3><a href=https://accessible-iot.org/publications/zhang2025pro/>Pro's Eyes: A Wearable System for Synchronous and Asynchronous Observational Pattern Learning</a></h3><p>Pro&rsquo;s Eyes is a wearable system that enables observational pattern learning from experts in both synchronous and asynchronous modes. The system captures and analyzes expert behavior patterns, facilitating skill transfer and learning through smart glasses technology.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/chen2025multimodal/>A Multimodal Wearable Sensing System for Vocal Muscle Biofeedback in Singing Pitch Training</a></h3><p>This paper presents a multimodal wearable sensing system designed to provide vocal muscle biofeedback during singing pitch training. The system helps users develop better control over their vocal muscles through real-time physiological feedback.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/hakkila2025biosensing/>Biosensing, Enhanced Senses and Experience Design for Augmented Humans</a></h3><p>This workshop paper explores the intersection of biosensing, enhanced senses, and experience design for augmented humans. It brings together researchers and practitioners to discuss how physiological sensing can create novel human augmentation experiences.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/peng2025conscious/>Conscious or Unconscious Meditation? Haptic Interaction Design in Meditation Augmentation Using Physiological Sensing</a></h3><p>This paper explores haptic interaction design for meditation augmentation, examining how physiological sensing can guide both conscious and unconscious meditation practices. The work investigates how different haptic feedback patterns can enhance meditative states.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/peng2025echosense/>EchoSense: Frontal Haptic Navigation in VR towards Biomimetic Empathy</a></h3><p>EchoSense presents a frontal haptic navigation system for VR environments that aims to foster biomimetic empathy. The system provides innovative haptic feedback for navigation, improving accessibility in virtual reality and enabling users to experience spatial awareness similar to biological echo-location.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/chen2025exploring/>Exploring Singing Breath: Physiological Insights and Directions for Breath-Aware Augmentation in Mixed Reality Design</a></h3><p>This paper explores the physiological aspects of singing breath control and proposes design directions for breath-aware augmentation in mixed reality. The work provides insights into respiratory patterns during singing and how they can be leveraged for immersive training experiences.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/chen2025introduction/>Introduction of the VCSD Dataset: A Vocal Cords Dataset Using EMG and Ultrasonography for Singing Pitch Skill Recognition</a></h3><p>This paper introduces VCSD (Vocal Cords for Singing Dataset), a novel dataset combining EMG and ultrasonography data for singing pitch skill recognition. The dataset provides a valuable resource for researchers working on vocal training systems and physiological sensing.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/gruenerbl20252nd/>2nd International Workshop on Mobile Cognitive-Augmenting and Cognition-Altering Technologies (CAT) in Human-Centered AI</a></h3><p>This workshop paper presents the second International Workshop on Mobile Cognitive-Augmenting and Cognition-Altering Technologies (mobiCHAI). Building on the first workshop, it continues to explore mobile technologies for cognitive augmentation within human-centered AI frameworks.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/xu2025spread/>Spread Your Wings: Demonstrating a Soft Floating Robotic Avatar with Flapping Wings for Novel Physical Interactions</a></h3><p>This demonstration presents a soft floating robotic avatar with flapping wings that enables novel forms of physical interaction. The robot builds on previous work (Cuddle robot) to explore how wing-based movements can create engaging and affective human-robot interactions.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/hansen2025bodypursuits/>BodyPursuits</a></h3><p>This research explores how the natural eye movement pattern of smooth pursuit can be used for interaction with IoT systems and wearable devices. By tracking how users&rsquo; eyes follow their own body motions, the system creates new opportunities for hands-free control.</p><p>The technique has particular relevance for accessibility, enabling people with limited hand mobility to interact with technology using natural body movements and gaze. It represents an innovative approach to inclusive interface design in the context of ubiquitous computing.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/kim2025eye/>Eye-Tracking for Cognitive Well-Being</a></h3><p>As eye-tracking becomes increasingly integrated into wearable devices and IoT systems, questions arise about how to ethically monitor and provide feedback about users&rsquo; cognitive states. This research addresses these concerns head-on, proposing design principles that prioritize user autonomy and well-being.</p><p>The work is particularly relevant for accessibility applications where cognitive monitoring could support people with attention difficulties, mental health challenges, or neurodivergent individuals, while respecting their privacy and agency.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/zaidi2025tieboard/>TIEboard: A Digital Educational Tool for Kids Geometric Learning</a></h3><p>TIEboard represents an innovative approach to making mathematics education more accessible and inclusive for children. By combining tangible interaction with digital feedback, the tool creates an engaging learning environment that supports diverse learning styles.</p><p>The research demonstrates how IoT-enabled educational tools can bridge the gap between abstract mathematical concepts and concrete, hands-on learning experiences.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/barbareschi2025sticking/>Sticking With Electronics for Crafting Practices</a></h3><p>This work addresses the digital divide by making electronics and IoT creation accessible to older adults. Through carefully designed crafting activities that incorporate electronics, the research shows how older adults can develop technical literacy while engaging in creative, meaningful activities.</p><p>The findings have important implications for inclusive design in IoT, showing that with appropriate support and methods, technology creation can be made accessible across age groups and technical backgrounds.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/xu2025cuddle/>Cuddle-Fish: Exploring a Soft Floating Robot with Flapping Wings for Physical Interactions</a></h3><p>Cuddle-Fish presents an innovative soft floating robot with flapping wings designed for safe physical interactions. The soft materials and gentle motion make it suitable for therapeutic and assistive applications, particularly in contexts requiring calming, non-threatening robotic presence.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/kikuchi2025mindspace/>MindSpace: Improving Relaxation Break and Performance Using a Device Exterting Tactile Sensation of Life-like Breathing Movement with Squeeze-like Deep Touch Pressure on Users' Upper Chest Area</a></h3><p>MindSpace is a novel device that provides tactile sensations mimicking life-like breathing movements with squeeze-like deep touch pressure on the upper chest area. The system is designed to improve relaxation breaks and enhance performance through calming haptic feedback.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/lepold2024openarable/>OpenEarable ExG: Open-Source Hardware for Ear-Based Biopotential Sensing Applications</a></h3><p>This paper introduces OpenEarable ExG, an innovative open-source hardware platform that democratizes ear-based biopotential sensing. By making the designs and schematics freely available, the research enables a wide range of applications in health monitoring, cognitive state detection, and accessibility tools.</p><p>The platform supports various biopotential signals including EOG (electrooculography), EMG (electromyography), and ECG (electrocardiography), all captured from the ear region. This positions OpenEarable as a key enabling technology for the Internet of Things in healthcare and accessibility contexts.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/elagroudy2024mobichai/>mobiCHAI 2024: 1st International Workshop on Mobile Cognitive-Augmenting and Cognition-Altering Technologies (CAT) in Human-Centered AI</a></h3><p>This workshop paper introduces the first International Workshop on Mobile Cognitive-Augmenting and Cognition-Altering Technologies (mobiCHAI). The workshop explores how mobile technologies can augment human cognitive capabilities within human-centered AI frameworks.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/barbareschi2024speech/>Speech is Silver, Silence is Golden</a></h3><p>This groundbreaking research explores the subtle communication patterns that enable visually impaired runners and their guides to move together effectively. The study reveals intricate verbal and non-verbal signaling strategies that have developed organically in the running community, providing insights for designing better assistive technologies for sports and physical activities.</p><p>Key findings include the importance of silence as a form of communication, indicating smooth coordination, and the role of micro-adjustments in maintaining synchronization between runner and guide.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/chen2024novel/>A Novel Sensing Method and Its Empirical Study for Vocal Technique Analysis of Singing Pitch Control: Combining Surface EMG with Ultrasonography</a></h3><p>This paper introduces a novel sensing method that combines surface EMG with ultrasonography to analyze vocal techniques during singing pitch control. The multimodal approach provides deeper insights into the physiological mechanisms of singing and opens new possibilities for vocal training systems.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/kanda2023soma/>Soma Express Kit</a></h3><p>This research introduces an innovative approach to understanding and sharing the embodied experiences of people with visual impairments. The Soma Express Kit uses IoT sensors and multi-sensory feedback to create new channels of communication between people with and without visual impairments.</p><p>By embracing the somaesthetic potential of people with visual impairments, this work fosters empathy and enables richer collaborative cross-ability interactions. The toolkit represents a significant contribution to inclusive IoT design, moving beyond traditional assistive technology paradigms.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/barbareschi2023robotic/>I am both here and there</a></h3><p>A groundbreaking study conducted in a real caf√© environment where disabled workers operated multiple robotic avatars in parallel. The research demonstrates that people with disabilities possess specific competencies that enhance their ability to manage multiple embodied presences simultaneously.</p><p>The findings have significant implications for employment opportunities and workplace accessibility, showing how assistive robotics can create new forms of meaningful work for people with mobility impairments.</p><p>This work was featured in multiple accessibility newsletters and demonstrates the practical application of IoT and robotics in creating inclusive workspaces.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/chen2023affective/>Affective Umbrella--A Wearable System to Visualize Heart and Electrodermal Activity, towards Emotion Regulation through Somaesthetic Appreciation</a></h3><p>The Affective Umbrella is a wearable system that visualizes heart and electrodermal activity in real-time. The work explores how somaesthetic appreciation of one&rsquo;s own physiological signals can support emotion regulation and self-awareness.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/li2023first/>First Bite/Chew: distinguish typical allergic food by two IMUs</a></h3><p>This paper presents a wearable system using two IMU sensors to detect typical allergic foods by analyzing bite and chew patterns. The work offers a novel approach to food allergy detection that could help users avoid allergen exposure.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/zhang2022seeing/>Seeing our Blind Spots</a></h3><p>Traditional visual impairment simulation tools are static and fail to account for dynamic eye movements. This research introduces a smart glasses-based system that provides realistic, dynamic simulations of various visual impairments.</p><p>The system was evaluated with design students, demonstrating significant improvements in their awareness and understanding of visual accessibility challenges. Questionnaires and qualitative feedback confirmed that the dynamic, eye-movement-aware simulation helped participants develop more empathetic and informed approaches to inclusive design.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/ragozin2022eyemove/>EyeMove-Towards Mobile Authentication using EOG Glasses</a></h3><p>EyeMove explores using EOG (electrooculography) glasses for mobile authentication. The system leverages eye movement patterns captured through wearable glasses as a biometric authentication method, offering a novel approach to secure access control.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/chen2022towards/>Towards Applying Pneumatic Gel Muscles to Augment Plantar Flexor Muscle Stretching for Children with Cerebral Palsy</a></h3><p>This paper explores the potential of Pneumatic Gel Muscles (PGM) technology for assisting children with cerebral palsy. The work investigates how soft actuators can be used to augment plantar flexor muscle stretching, offering a novel approach to rehabilitation therapy.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/malaver2022ethereal/>Ethereal Phenomena-Interactive Art, Meditation, and Breathing Biofeedback: From Mind and Body Wellness Towards Self-Transcendence</a></h3><p>This extended work on Ethereal Phenomena presents an interactive art installation that uses breathing biofeedback to facilitate meditation and self-transcendence. The system bridges mind-body wellness practices with technological augmentation through real-time physiological sensing and visualization.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/semertzidis2022human/>Human--Computer Integration: Towards Integrating the Human Body with the Computational Machine</a></h3><p>This comprehensive survey paper establishes the theoretical foundations for human-computer integration (HCI), exploring how the human body can be integrated with computational machines. The work provides a framework for understanding and advancing research in human augmentation and embodied interaction.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/malaver2021ethereal/>Ethereal Phenomena</a></h3><p>Ethereal Phenomena is an interactive art installation that explores the connection between meditation, breathing patterns, and visual representation. The work uses biofeedback to create immersive experiences that visualize physiological states.</p></article><article class=card><h3><a href=https://accessible-iot.org/publications/chen2021affective/>Affective Umbrella--Towards a Novel Sensor Integrated Multimedia Platform Using Electrodermal and Heart Activity in an Umbrella Handle</a></h3><p>This paper introduces the Affective Umbrella, a novel platform that integrates electrodermal and heart activity sensors into an umbrella handle. The system explores unobtrusive physiological monitoring in everyday situations, turning a common object into a wearable sensing device.</p></article></div></main></div></body></html>